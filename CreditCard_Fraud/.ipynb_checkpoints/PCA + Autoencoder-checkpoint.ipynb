{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43581be7",
   "metadata": {},
   "source": [
    "Reference : https://towardsdatascience.com/fraud-detection-unsupervised-anomaly-detection-df43d81fce67"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69330f63",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892e8ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 17:38:25.021280: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc15f78",
   "metadata": {},
   "source": [
    "## Data Load & Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdb3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/yjhwang/finance/CreditCard_Fraud/data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af104d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>1.420255e+05</td>\n",
       "      <td>82248.545392</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>70796.750000</td>\n",
       "      <td>141722.000000</td>\n",
       "      <td>213359.500000</td>\n",
       "      <td>284803.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>1.972910e-04</td>\n",
       "      <td>1.951060</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.923479</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>1.315373</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>1.288795e-03</td>\n",
       "      <td>1.651064</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.595602</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.801687</td>\n",
       "      <td>21.467203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>9.717363e-03</td>\n",
       "      <td>1.496916</td>\n",
       "      <td>-32.454198</td>\n",
       "      <td>-0.883877</td>\n",
       "      <td>0.183868</td>\n",
       "      <td>1.037120</td>\n",
       "      <td>4.187811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-4.169208e-03</td>\n",
       "      <td>1.412633</td>\n",
       "      <td>-5.600607</td>\n",
       "      <td>-0.853728</td>\n",
       "      <td>-0.019359</td>\n",
       "      <td>0.742208</td>\n",
       "      <td>16.491217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>4.749962e-04</td>\n",
       "      <td>1.367533</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-0.689853</td>\n",
       "      <td>-0.054060</td>\n",
       "      <td>0.614214</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>5.141158e-03</td>\n",
       "      <td>1.330583</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.766094</td>\n",
       "      <td>-0.272436</td>\n",
       "      <td>0.405285</td>\n",
       "      <td>23.917837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>5.769024e-03</td>\n",
       "      <td>1.204111</td>\n",
       "      <td>-41.506796</td>\n",
       "      <td>-0.552071</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>44.054461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-2.450588e-03</td>\n",
       "      <td>1.185504</td>\n",
       "      <td>-50.943369</td>\n",
       "      <td>-0.209492</td>\n",
       "      <td>0.020970</td>\n",
       "      <td>0.328303</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-2.107069e-03</td>\n",
       "      <td>1.095415</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.647477</td>\n",
       "      <td>-0.052157</td>\n",
       "      <td>0.590705</td>\n",
       "      <td>10.392889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>5.209413e-03</td>\n",
       "      <td>1.071337</td>\n",
       "      <td>-24.403185</td>\n",
       "      <td>-0.533477</td>\n",
       "      <td>-0.090810</td>\n",
       "      <td>0.455287</td>\n",
       "      <td>15.331742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-1.686401e-03</td>\n",
       "      <td>1.014689</td>\n",
       "      <td>-4.682931</td>\n",
       "      <td>-0.763105</td>\n",
       "      <td>-0.034405</td>\n",
       "      <td>0.739737</td>\n",
       "      <td>10.446847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>3.944337e-03</td>\n",
       "      <td>0.977039</td>\n",
       "      <td>-18.553697</td>\n",
       "      <td>-0.402650</td>\n",
       "      <td>0.141434</td>\n",
       "      <td>0.619635</td>\n",
       "      <td>4.318071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>2.043291e-03</td>\n",
       "      <td>0.994908</td>\n",
       "      <td>-3.844974</td>\n",
       "      <td>-0.647334</td>\n",
       "      <td>-0.010847</td>\n",
       "      <td>0.663362</td>\n",
       "      <td>4.569009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>4.397323e-03</td>\n",
       "      <td>0.933753</td>\n",
       "      <td>-15.623187</td>\n",
       "      <td>-0.423962</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>0.494116</td>\n",
       "      <td>7.518403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-5.004147e-04</td>\n",
       "      <td>0.915666</td>\n",
       "      <td>-4.152532</td>\n",
       "      <td>-0.584307</td>\n",
       "      <td>0.048524</td>\n",
       "      <td>0.646540</td>\n",
       "      <td>5.784514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>2.905432e-03</td>\n",
       "      <td>0.864903</td>\n",
       "      <td>-13.303888</td>\n",
       "      <td>-0.467574</td>\n",
       "      <td>0.066434</td>\n",
       "      <td>0.525120</td>\n",
       "      <td>8.289890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>3.397329e-03</td>\n",
       "      <td>0.808552</td>\n",
       "      <td>-21.297906</td>\n",
       "      <td>-0.486154</td>\n",
       "      <td>-0.066939</td>\n",
       "      <td>0.397480</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>1.114402e-03</td>\n",
       "      <td>0.830763</td>\n",
       "      <td>-8.668815</td>\n",
       "      <td>-0.497362</td>\n",
       "      <td>-0.004633</td>\n",
       "      <td>0.500335</td>\n",
       "      <td>4.295648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>3.000598e-04</td>\n",
       "      <td>0.814542</td>\n",
       "      <td>-4.932733</td>\n",
       "      <td>-0.456712</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.461655</td>\n",
       "      <td>4.715142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-4.995680e-04</td>\n",
       "      <td>0.763326</td>\n",
       "      <td>-28.009635</td>\n",
       "      <td>-0.211935</td>\n",
       "      <td>-0.062891</td>\n",
       "      <td>0.133381</td>\n",
       "      <td>26.237391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-1.242469e-03</td>\n",
       "      <td>0.722001</td>\n",
       "      <td>-22.757540</td>\n",
       "      <td>-0.229710</td>\n",
       "      <td>-0.030281</td>\n",
       "      <td>0.186001</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>4.088347e-07</td>\n",
       "      <td>0.723829</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-0.540266</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.528751</td>\n",
       "      <td>8.361985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-1.317418e-03</td>\n",
       "      <td>0.636061</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.162180</td>\n",
       "      <td>-0.012261</td>\n",
       "      <td>0.147474</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-8.841494e-04</td>\n",
       "      <td>0.605854</td>\n",
       "      <td>-2.824849</td>\n",
       "      <td>-0.355582</td>\n",
       "      <td>0.040573</td>\n",
       "      <td>0.438225</td>\n",
       "      <td>4.022866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>1.680154e-03</td>\n",
       "      <td>0.520069</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.315470</td>\n",
       "      <td>0.018278</td>\n",
       "      <td>0.353989</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-2.933701e-04</td>\n",
       "      <td>0.480979</td>\n",
       "      <td>-1.855355</td>\n",
       "      <td>-0.326160</td>\n",
       "      <td>-0.052815</td>\n",
       "      <td>0.240838</td>\n",
       "      <td>3.119295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-2.337128e-04</td>\n",
       "      <td>0.399505</td>\n",
       "      <td>-9.895244</td>\n",
       "      <td>-0.070847</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.091279</td>\n",
       "      <td>11.135740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>-5.080546e-04</td>\n",
       "      <td>0.356130</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>-0.053249</td>\n",
       "      <td>0.011158</td>\n",
       "      <td>0.077851</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V29</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>9.272530e-01</td>\n",
       "      <td>3.412933</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>-0.230560</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>0.768532</td>\n",
       "      <td>180.101027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V30</th>\n",
       "      <td>113842.0</td>\n",
       "      <td>1.162315e-01</td>\n",
       "      <td>0.558161</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.360304</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>0.640653</td>\n",
       "      <td>1.034951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count          mean           std        min           25%  \\\n",
       "ID   113842.0  1.420255e+05  82248.545392   3.000000  70796.750000   \n",
       "V1   113842.0  1.972910e-04      1.951060 -56.407510     -0.923479   \n",
       "V2   113842.0  1.288795e-03      1.651064 -72.715728     -0.595602   \n",
       "V3   113842.0  9.717363e-03      1.496916 -32.454198     -0.883877   \n",
       "V4   113842.0 -4.169208e-03      1.412633  -5.600607     -0.853728   \n",
       "V5   113842.0  4.749962e-04      1.367533 -42.147898     -0.689853   \n",
       "V6   113842.0  5.141158e-03      1.330583 -26.160506     -0.766094   \n",
       "V7   113842.0  5.769024e-03      1.204111 -41.506796     -0.552071   \n",
       "V8   113842.0 -2.450588e-03      1.185504 -50.943369     -0.209492   \n",
       "V9   113842.0 -2.107069e-03      1.095415 -13.434066     -0.647477   \n",
       "V10  113842.0  5.209413e-03      1.071337 -24.403185     -0.533477   \n",
       "V11  113842.0 -1.686401e-03      1.014689  -4.682931     -0.763105   \n",
       "V12  113842.0  3.944337e-03      0.977039 -18.553697     -0.402650   \n",
       "V13  113842.0  2.043291e-03      0.994908  -3.844974     -0.647334   \n",
       "V14  113842.0  4.397323e-03      0.933753 -15.623187     -0.423962   \n",
       "V15  113842.0 -5.004147e-04      0.915666  -4.152532     -0.584307   \n",
       "V16  113842.0  2.905432e-03      0.864903 -13.303888     -0.467574   \n",
       "V17  113842.0  3.397329e-03      0.808552 -21.297906     -0.486154   \n",
       "V18  113842.0  1.114402e-03      0.830763  -8.668815     -0.497362   \n",
       "V19  113842.0  3.000598e-04      0.814542  -4.932733     -0.456712   \n",
       "V20  113842.0 -4.995680e-04      0.763326 -28.009635     -0.211935   \n",
       "V21  113842.0 -1.242469e-03      0.722001 -22.757540     -0.229710   \n",
       "V22  113842.0  4.088347e-07      0.723829  -8.887017     -0.540266   \n",
       "V23  113842.0 -1.317418e-03      0.636061 -44.807735     -0.162180   \n",
       "V24  113842.0 -8.841494e-04      0.605854  -2.824849     -0.355582   \n",
       "V25  113842.0  1.680154e-03      0.520069 -10.295397     -0.315470   \n",
       "V26  113842.0 -2.933701e-04      0.480979  -1.855355     -0.326160   \n",
       "V27  113842.0 -2.337128e-04      0.399505  -9.895244     -0.070847   \n",
       "V28  113842.0 -5.080546e-04      0.356130  -9.617915     -0.053249   \n",
       "V29  113842.0  9.272530e-01      3.412933  -0.307413     -0.230560   \n",
       "V30  113842.0  1.162315e-01      0.558161  -0.994972     -0.360304   \n",
       "\n",
       "               50%            75%            max  \n",
       "ID   141722.000000  213359.500000  284803.000000  \n",
       "V1        0.012074       1.315373       2.454930  \n",
       "V2        0.066390       0.801687      21.467203  \n",
       "V3        0.183868       1.037120       4.187811  \n",
       "V4       -0.019359       0.742208      16.491217  \n",
       "V5       -0.054060       0.614214      34.801666  \n",
       "V6       -0.272436       0.405285      23.917837  \n",
       "V7        0.039036       0.568750      44.054461  \n",
       "V8        0.020970       0.328303      20.007208  \n",
       "V9       -0.052157       0.590705      10.392889  \n",
       "V10      -0.090810       0.455287      15.331742  \n",
       "V11      -0.034405       0.739737      10.446847  \n",
       "V12       0.141434       0.619635       4.318071  \n",
       "V13      -0.010847       0.663362       4.569009  \n",
       "V14       0.052157       0.494116       7.518403  \n",
       "V15       0.048524       0.646540       5.784514  \n",
       "V16       0.066434       0.525120       8.289890  \n",
       "V17      -0.066939       0.397480       9.253526  \n",
       "V18      -0.004633       0.500335       4.295648  \n",
       "V19       0.004657       0.461655       4.715142  \n",
       "V20      -0.062891       0.133381      26.237391  \n",
       "V21      -0.030281       0.186001      27.202839  \n",
       "V22       0.008346       0.528751       8.361985  \n",
       "V23      -0.012261       0.147474      22.528412  \n",
       "V24       0.040573       0.438225       4.022866  \n",
       "V25       0.018278       0.353989       7.519589  \n",
       "V26      -0.052815       0.240838       3.119295  \n",
       "V27       0.001502       0.091279      11.135740  \n",
       "V28       0.011158       0.077851      33.847808  \n",
       "V29      -0.000699       0.768532     180.101027  \n",
       "V30      -0.002590       0.640653       1.034951  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c59120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394a66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"/home/yjhwang/finance/CreditCard_Fraud/data/val.csv\")\n",
    "val_x = val_df.drop(columns=['ID', 'Class']) # Input Data\n",
    "val_y = val_df['Class'] # Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370756c9",
   "metadata": {},
   "source": [
    "The main idea of this approach is to compress the data making a \"latent representation\" and then reconstruct the data. If a sample is similar to the rest of the dataset, the reconstructed data will be similar or even equal to the original data. However, if the sample is not similar to the rest, the reconstructed sample will not be similar to the original one. In short, we compress the data and reconstruct it. If the reconstructed data is not similar to the original one, we have a fraud. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e812d",
   "metadata": {},
   "source": [
    "### Using PCA - fit with train set\n",
    "We compress the data from 30 features to 10 features and calculated the reconstruction score. The histogram for this score is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d72823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for n in range(2, 31):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(train_x)\n",
    "    X_tt = pca.transform(train_x)\n",
    "    X_dt = pca.inverse_transform(X_tt)\n",
    "    \n",
    "    scores.append(mean_squared_error(train_x, X_dt))\n",
    "scores = np.array(scores)\n",
    "print(scores.argmin() + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f63bd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 10\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "pca.fit(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e935be8",
   "metadata": {},
   "source": [
    "### Val eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895bb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tt = pca.transform(val_x)\n",
    "X_dt = pca.inverse_transform(X_tt)\n",
    "X_dt = pd.DataFrame(X_dt, columns=val_x.columns, index=val_x.index)\n",
    "\n",
    "reconstruction_score = []\n",
    "for idx in val_x.index:\n",
    "    score = mean_squared_error(val_x.loc[idx], X_dt.loc[idx])\n",
    "    reconstruction_score.append(score)\n",
    "    \n",
    "rc_scores = pd.DataFrame(reconstruction_score, index=val_x.index, columns=['reconstruction_score'])\n",
    "\n",
    "rec_mean = rc_scores['reconstruction_score'].mean()\n",
    "rec_median = rc_scores['reconstruction_score'].median()\n",
    "rec_std = rc_scores['reconstruction_score'].std()\n",
    "\n",
    "rc_scores = rc_scores.sort_values(by='reconstruction_score', ascending=False)\n",
    "\n",
    "top_scores_idx = rc_scores[(rc_scores > (rec_median + 2*rec_std))].dropna().index\n",
    "val_fraud_index = list(val_y[val_y == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b649edb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     28432\n",
      "           1       0.14      0.80      0.24        30\n",
      "\n",
      "    accuracy                           0.99     28462\n",
      "   macro avg       0.57      0.90      0.62     28462\n",
      "weighted avg       1.00      0.99      1.00     28462\n",
      "\n",
      "Rate of transations to investigate: 0.5972876115522451 %\n"
     ]
    }
   ],
   "source": [
    "pred = pd.DataFrame(index=val_x.index)\n",
    "pred['fraud'] = 0\n",
    "for x in top_scores_idx:\n",
    "    pred['fraud'].loc[x] = 1\n",
    "    \n",
    "print(classification_report(val_y, pred['fraud']))\n",
    "print('Rate of transations to investigate:', len(top_scores_idx) / len(val_x) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6844ba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28457</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28458</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28459</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28460</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28461</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28462 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fraud\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "28457      0\n",
       "28458      0\n",
       "28459      0\n",
       "28460      0\n",
       "28461      0\n",
       "\n",
       "[28462 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86f693",
   "metadata": {},
   "source": [
    "## Using autoencoder\n",
    "Composes of encoder & decoder  \n",
    "encoder: responsable to compress the data  \n",
    "decoder: reconstruct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6fd50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_tscaled = ss.fit_transform(train_x.values)\n",
    "train_x = pd.DataFrame(X_tscaled, columns=train_x.columns, index=train_x.index)\n",
    "\n",
    "X_vscaled = ss.transform(val_x.values)\n",
    "val_x = pd.DataFrame(X_vscaled, columns=val_x.columns, index=val_x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b05836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                3030      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,830\n",
      "Trainable params: 18,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 17:38:54.153116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-07 17:38:54.154039: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-07 17:38:54.163507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "inp = Input(shape=(train_x.shape[1]))\n",
    "\n",
    "# Encoder\n",
    "x = Dense(100, activation='relu')(inp)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "\n",
    "# Decoder\n",
    "x = Dense(50, activation='tanh')(x)\n",
    "x = Dense(100, activation='tanh')(x)\n",
    "\n",
    "## output\n",
    "output = Dense(train_x.shape[1], activation='relu')(x)\n",
    "\n",
    "autoencoder = Model(inp, output)\n",
    "\n",
    "lr = 0.0001\n",
    "epochs = 300\n",
    "adam = Adam(lr=lr, decay=(lr/epochs))\n",
    "\n",
    "autoencoder.compile(optimizer=adam, loss=\"mean_squared_error\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20eb2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(train_x.values,train_x.values, batch_size=2048, epochs=epochs,\n",
    "                          shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29dc867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and validation loss')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "ts = range(epochs)\n",
    "\n",
    "plt.plot(ts, loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac86e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "encoder.add(autoencoder.layers[1])\n",
    "encoder.add(autoencoder.layers[2])\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(autoencoder.layers[3])\n",
    "decoder.add(autoencoder.layers[4])\n",
    "decoder.add(autoencoder.layers[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473cb3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890/890 [==============================] - 1s 1ms/step\n",
      "890/890 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "X_tt = encoder.predict(val_x)\n",
    "X_dt = decoder.predict(X_tt)\n",
    "X_dt = pd.DataFrame(X_dt, columns=val_x.columns, index=val_x.index)\n",
    "\n",
    "reconstruction_score = []\n",
    "for idx in val_x.index:\n",
    "    score = mean_squared_error(val_x.loc[idx], X_dt.loc[idx])\n",
    "    reconstruction_score.append(score)\n",
    "    \n",
    "rc_scores = pd.DataFrame(reconstruction_score, index=val_x.index, columns=['reconstruction_score'])\n",
    "\n",
    "rec_mean = rc_scores['reconstruction_score'].mean()\n",
    "rec_median = rc_scores['reconstruction_score'].median()\n",
    "rec_std = rc_scores['reconstruction_score'].std()\n",
    "rc_scores = rc_scores.sort_values(by='reconstruction_score', ascending=False)\n",
    "\n",
    "top_scores_idx = rc_scores[(rc_scores > (rec_median + 2*rec_std))].dropna().index\n",
    "val_fraud_index = list(val_y[val_y == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4143034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([15054, 15345,  4396,  6350,  4267, 15030, 15029, 15027,  7890,\n",
       "              836,\n",
       "            ...\n",
       "            18263, 22784, 23114, 11025, 20410, 19833,  7659, 12530,  2665,\n",
       "            14718],\n",
       "           dtype='int64', length=243)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_scores_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9e1e808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     28432\n",
      "           1       0.09      0.70      0.15        30\n",
      "\n",
      "    accuracy                           0.99     28462\n",
      "   macro avg       0.54      0.85      0.57     28462\n",
      "weighted avg       1.00      0.99      1.00     28462\n",
      "\n",
      "Rate of transations to investigate: 0.8537699388658563 %\n"
     ]
    }
   ],
   "source": [
    "pred = pd.DataFrame(index=val_x.index)\n",
    "pred['fraud'] = 0\n",
    "for x in top_scores_idx:\n",
    "    pred['fraud'].loc[x] = 1\n",
    "\n",
    "print(classification_report(val_y, pred['fraud']))\n",
    "print('Rate of transations to investigate:', len(top_scores_idx) / len(val_x) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39116c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
